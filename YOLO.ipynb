{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjXS6telz-5x"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D,Activation, SpatialDropout2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SeparableConv2D\n",
        "from keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "lx9WjTVB0hUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnHrFckr0hZk",
        "outputId": "ae7db2b8-7a44-4645-e424-c5e74b95562e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdgen = ImageDataGenerator(\n",
        "    featurewise_center = False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center = False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization = False,  # divide each input by its std\n",
        "    zca_whitening = False,  # apply ZCA whitening\n",
        "    rotation_range = 15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range = 0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range = 0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip = True,  # randomly flip images\n",
        "    vertical_flip = False,  # randomly flip images\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        ")\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "imdgen.fit(x_train)\n",
        "\n",
        "# fit the model on the batches generated by datagen.flow()\n",
        "dgen = imdgen.flow(x_train, y_train, batch_size=128)"
      ],
      "metadata": {
        "id": "KVGqYR9X0hbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For reproducibility\n",
        "np.random.seed(1000)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), strides=(1,1), padding='same', use_bias=False, input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "for i in range(0,3):\n",
        "    model.add(Conv2D(32*(2**i), (3,3), strides=(1,1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "checkpoint = ModelCheckpoint(\"CIFAR_10_YOLO_with_dropout.h5\", monitor='val_loss', verbose=2, save_best_only=True, mode='min',save_weights_only=True)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adamax',\n",
        "              metrics=['categorical_accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akps-ojm0heL",
        "outputId": "8afac25e-5cbb-41dd-fc29-01f1a8fc89d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 16)        432       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 16)       64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        4608      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 64)          18432     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 128)         73728     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 2, 2, 512)         589824    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 2, 2, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 710,522\n",
            "Trainable params: 709,018\n",
            "Non-trainable params: 1,504\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train,batch_size=128,epochs=10,validation_data=(x_test, y_test),callbacks=callbacks_list,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXnezKou0hhV",
        "outputId": "d572aec3-b2b4-46d6-a209-8210632b4a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8974 - categorical_accuracy: 0.3333\n",
            "Epoch 1: val_loss improved from inf to 1.89173, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 179s 454ms/step - loss: 1.8974 - categorical_accuracy: 0.3333 - val_loss: 1.8917 - val_categorical_accuracy: 0.3810\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5687 - categorical_accuracy: 0.4325\n",
            "Epoch 2: val_loss did not improve from 1.89173\n",
            "391/391 [==============================] - 169s 431ms/step - loss: 1.5687 - categorical_accuracy: 0.4325 - val_loss: 1.8951 - val_categorical_accuracy: 0.3471\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4204 - categorical_accuracy: 0.4871\n",
            "Epoch 3: val_loss did not improve from 1.89173\n",
            "391/391 [==============================] - 169s 432ms/step - loss: 1.4204 - categorical_accuracy: 0.4871 - val_loss: 1.9338 - val_categorical_accuracy: 0.3560\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3162 - categorical_accuracy: 0.5240\n",
            "Epoch 4: val_loss improved from 1.89173 to 1.54912, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 168s 429ms/step - loss: 1.3162 - categorical_accuracy: 0.5240 - val_loss: 1.5491 - val_categorical_accuracy: 0.4513\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2407 - categorical_accuracy: 0.5498\n",
            "Epoch 5: val_loss improved from 1.54912 to 1.36783, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 169s 433ms/step - loss: 1.2407 - categorical_accuracy: 0.5498 - val_loss: 1.3678 - val_categorical_accuracy: 0.5233\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1728 - categorical_accuracy: 0.5774\n",
            "Epoch 6: val_loss improved from 1.36783 to 1.14753, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 173s 443ms/step - loss: 1.1728 - categorical_accuracy: 0.5774 - val_loss: 1.1475 - val_categorical_accuracy: 0.5893\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1242 - categorical_accuracy: 0.5957\n",
            "Epoch 7: val_loss did not improve from 1.14753\n",
            "391/391 [==============================] - 174s 446ms/step - loss: 1.1242 - categorical_accuracy: 0.5957 - val_loss: 1.2212 - val_categorical_accuracy: 0.5690\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0769 - categorical_accuracy: 0.6150\n",
            "Epoch 8: val_loss improved from 1.14753 to 1.08815, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 175s 448ms/step - loss: 1.0769 - categorical_accuracy: 0.6150 - val_loss: 1.0882 - val_categorical_accuracy: 0.6140\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0404 - categorical_accuracy: 0.6267\n",
            "Epoch 9: val_loss improved from 1.08815 to 1.04004, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 171s 438ms/step - loss: 1.0404 - categorical_accuracy: 0.6267 - val_loss: 1.0400 - val_categorical_accuracy: 0.6276\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0033 - categorical_accuracy: 0.6417\n",
            "Epoch 10: val_loss improved from 1.04004 to 0.98835, saving model to CIFAR_10_YOLO_with_dropout.h5\n",
            "391/391 [==============================] - 168s 430ms/step - loss: 1.0033 - categorical_accuracy: 0.6417 - val_loss: 0.9884 - val_categorical_accuracy: 0.6477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa15c81ce10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse = model.evaluate(x_train, y_train, verbose=0)\n",
        "test_mse = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "6KUZO8AL1AWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train loss : %.3f %% , Test loss : %.3f %%' % (train_mse[0]*100, test_mse[0]*100))\n",
        "print('Train accuracy : %.3f %% , Test accuracy : %.3f %%' % (train_mse[1]*100, test_mse[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7x1E3451AYX",
        "outputId": "d718957d-1f49-4365-e117-de0b128b4188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss : 93.024 % , Test loss : 98.835 %\n",
            "Train accuracy : 66.686 % , Test accuracy : 64.770 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ExhLN7bV0hlU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}